{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# SA_SLM 학습 노트북\n",
        "\n",
        "## 필요 파일\n",
        "- `data.zip`: 로컬 `data/` 폴더를 ZIP 압축\n",
        "\n",
        "## 실행 전\n",
        "런타임 > 런타임 유형 변경 > **GPU (T4)** 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# 1. 환경 설정\n",
        "!pip install -q torch transformers datasets accelerate peft bitsandbytes trl\n",
        "!pip install -U bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload"
      },
      "outputs": [],
      "source": [
        "# 2. 데이터 업로드\n",
        "from google.colab import files\n",
        "import zipfile, os, json, glob\n",
        "\n",
        "print('data.zip 파일을 업로드하세요')\n",
        "uploaded = files.upload()\n",
        "\n",
        "for f in uploaded:\n",
        "    if f.endswith('.zip'):\n",
        "        zipfile.ZipFile(f).extractall('.')\n",
        "        print(f'{f} 압축 해제 완료')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load"
      },
      "outputs": [],
      "source": [
        "# 3. 데이터 로드\n",
        "records = [json.load(open(f)) for f in \n",
        "           glob.glob('./data/examples/student_record*.json') + \n",
        "           glob.glob('./data/raw/students/*.json')]\n",
        "\n",
        "tasks = {}\n",
        "for k, v in [('roadmap', 'test_task1_roadmap.json'),\n",
        "             ('statement', 'test_task2_statement.json'),\n",
        "             ('evaluation', 'test_task3_evaluation.json')]:\n",
        "    p = './data/examples/' + v\n",
        "    if os.path.exists(p):\n",
        "        tasks[k] = json.load(open(p))\n",
        "\n",
        "print(f'{len(records)} records, {sum(len(v) for v in tasks.values())} tasks')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "convert"
      },
      "outputs": [],
      "source": [
        "# 4. 학습 데이터 변환 (Schema v2)\n",
        "examples = []\n",
        "\n",
        "for r in records:\n",
        "    # 신 스키마 v2 구조\n",
        "    school = r.get('school_info', {})\n",
        "    grades = r.get('grades', {})\n",
        "    major = r.get('target_major', {})\n",
        "    acts_obj = r.get('activities', {})\n",
        "    notes = r.get('consultant_notes', {})\n",
        "    result = r.get('admission_result', {})\n",
        "    \n",
        "    # 교과 + 비교과 활동 통합\n",
        "    all_acts = acts_obj.get('curricular', []) + acts_obj.get('extracurricular', [])\n",
        "    \n",
        "    # 프로필 문자열 생성\n",
        "    pstr = f\"지역:{school.get('region','')} 학교:{school.get('school_type','')} 계열:{major.get('track','')} 성적:{grades.get('overall_tier','')} 관심:{','.join(major.get('interests',[]))} 가치관:{','.join(major.get('values',[]))} 목표:{major.get('specific','')}\"\n",
        "    \n",
        "    # 차별화된 활동 (점수 4 이상)\n",
        "    astr = ''.join([f\"\\n-[{a.get('category','')}]{a.get('description','')}\" for a in all_acts if a.get('uniqueness_score',0)>=4])\n",
        "    \n",
        "    # 활동 추천 예시\n",
        "    examples.append({'i': '활동추천', 'in': pstr, 'out': f\"[추천]{astr}\\n[서사]{notes.get('narrative_summary','')}\"})\n",
        "    \n",
        "    # 세특 작성 예시\n",
        "    for a in all_acts:\n",
        "        if a.get('neis_statement'):\n",
        "            examples.append({'i': '세특작성', 'in': f\"과목:{a.get('subject','')} 활동:{a.get('description','')}\", 'out': a.get('neis_statement','')})\n",
        "\n",
        "# 기존 task 파일 처리 (하위 호환)\n",
        "for item in tasks.get('roadmap', []):\n",
        "    inp = item.get('input', {})\n",
        "    examples.append({'i': item.get('instruction',''), 'in': f\"계열:{inp.get('track','')}\", 'out': item.get('output','')})\n",
        "\n",
        "for item in tasks.get('statement', []):\n",
        "    inp = item.get('input', {})\n",
        "    examples.append({'i': item.get('instruction',''), 'in': f\"과목:{inp.get('subject','')} 활동:{inp.get('raw_activity','')}\", 'out': item.get('output','')})\n",
        "\n",
        "print(f'{len(examples)} examples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dataset"
      },
      "outputs": [],
      "source": [
        "# 5. Dataset 생성\n",
        "from datasets import Dataset\n",
        "\n",
        "def fmt(e):\n",
        "    return {'text': f\"<|im_start|>system\\n생기부전문가<|im_end|>\\n<|im_start|>user\\n{e['i']}\\n{e['in']}<|im_end|>\\n<|im_start|>assistant\\n{e['out']}<|im_end|>\"}\n",
        "\n",
        "dataset = Dataset.from_list([fmt(e) for e in examples])\n",
        "print(f'{len(dataset)} samples')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model"
      },
      "outputs": [],
      "source": [
        "# 6. 모델 로드 + LoRA 설정\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
        "\n",
        "MODEL = 'Qwen/Qwen2.5-3B-Instruct'\n",
        "\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL, quantization_config=bnb, device_map='auto', trust_remote_code=True\n",
        ")\n",
        "model = prepare_model_for_kbit_training(model)\n",
        "\n",
        "lora = LoraConfig(\n",
        "    r=16, lora_alpha=32,\n",
        "    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],\n",
        "    lora_dropout=0.05, bias='none', task_type='CAUSAL_LM'\n",
        ")\n",
        "model = get_peft_model(model, lora)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "train"
      },
      "outputs": [],
      "source": [
        "# 7. 학습\n",
        "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir='./out',\n",
        "    num_train_epochs=10, # 3 -> 10\n",
        "    per_device_train_batch_size=1,\n",
        "    gradient_accumulation_steps=4,\n",
        "    learning_rate=1e-4, # 2e-4 -> 1e-4\n",
        "    warmup_ration=0.05, # 새롭게 추가\n",
        "    bf16=True,\n",
        "    logging_steps=10,\n",
        "    save_strategy='epoch',\n",
        "    optim='paged_adamw_8bit',\n",
        "    report_to='none'\n",
        ")\n",
        "\n",
        "def tokenize(example):\n",
        "    return tokenizer(example['text'], truncation=True, max_length=2048, padding='max_length')\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, remove_columns=['text'])\n",
        "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=tokenized_dataset,\n",
        "    data_collator=collator\n",
        ")\n",
        "\n",
        "print(f'Training {len(tokenized_dataset)} samples...')\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "save"
      },
      "outputs": [],
      "source": [
        "# 8. 저장 & 다운로드\n",
        "import shutil\n",
        "\n",
        "model.save_pretrained('./adapter')\n",
        "tokenizer.save_pretrained('./adapter')\n",
        "shutil.make_archive('sa_slm_adapter', 'zip', '.', './adapter')\n",
        "\n",
        "print('다운로드 시작...')\n",
        "files.download('sa_slm_adapter.zip')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
