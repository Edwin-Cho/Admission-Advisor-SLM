{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {"provenance": [], "gpuType": "T4"},
    "kernelspec": {"name": "python3", "display_name": "Python 3"},
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": ["# SA_SLM 학습 노트북\n\n", "## 필요 파일\n", "- `data.zip`: 로컬 `data/` 폴더를 ZIP 압축\n\n", "## 실행 전\n", "런타임 > 런타임 유형 변경 > **GPU (T4)** 선택"],
      "metadata": {"id": "header"}
    },
    {
      "cell_type": "code",
      "source": ["# 1. 환경 설정\n", "!pip install -q torch transformers datasets accelerate peft bitsandbytes trl\n", "!pip install -U bitsandbytes"],
      "metadata": {"id": "install"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 2. 데이터 업로드\n", "from google.colab import files\n", "import zipfile, os, json, glob\n\n", "print('data.zip 파일을 업로드하세요')\n", "uploaded = files.upload()\n\n", "for f in uploaded:\n", "    if f.endswith('.zip'):\n", "        zipfile.ZipFile(f).extractall('.')\n", "        print(f'{f} 압축 해제 완료')"],
      "metadata": {"id": "upload"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 3. 데이터 로드\n", "records = [json.load(open(f)) for f in \n", "           glob.glob('./data/examples/student_record*.json') + \n", "           glob.glob('./data/raw/students/*.json')]\n\n", "tasks = {}\n", "for k, v in [('roadmap', 'test_task1_roadmap.json'),\n", "             ('statement', 'test_task2_statement.json'),\n", "             ('evaluation', 'test_task3_evaluation.json')]:\n", "    p = './data/examples/' + v\n", "    if os.path.exists(p):\n", "        tasks[k] = json.load(open(p))\n\n", "print(f'{len(records)} records, {sum(len(v) for v in tasks.values())} tasks')"],
      "metadata": {"id": "load"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 4. 학습 데이터 변환\n", "examples = []\n\n", "for r in records:\n", "    p = r.get('profile', {})\n", "    res = r.get('admission_result', {})\n", "    acts = r.get('activities', [])\n", "    n = r.get('consultant_notes', {})\n", "    \n", "    pstr = f\"계열:{p.get('track','')} 성적:{p.get('grade_tier','')} 관심:{','.join(p.get('interests',[]))} 가치관:{','.join(p.get('values',[]))} 목표:{res.get('major_category','')}\"\n", "    astr = ''.join([f\"\\n-[{a.get('category','')}]{a.get('description','')}\" for a in acts if a.get('uniqueness_score',0)>=4])\n", "    \n", "    examples.append({'i': '활동추천', 'in': pstr, 'out': f\"[추천]{astr}\\n[서사]{n.get('narrative_summary','')}\"})\n", "    \n", "    for a in acts:\n", "        if a.get('neis_statement'):\n", "            examples.append({'i': '세특작성', 'in': f\"과목:{a.get('subject','')} 활동:{a.get('description','')}\", 'out': a.get('neis_statement','')})\n\n", "for item in tasks.get('roadmap', []):\n", "    inp = item.get('input', {})\n", "    examples.append({'i': item.get('instruction',''), 'in': f\"계열:{inp.get('track','')}\", 'out': item.get('output','')})\n\n", "for item in tasks.get('statement', []):\n", "    inp = item.get('input', {})\n", "    examples.append({'i': item.get('instruction',''), 'in': f\"과목:{inp.get('subject','')} 활동:{inp.get('raw_activity','')}\", 'out': item.get('output','')})\n\n", "print(f'{len(examples)} examples')"],
      "metadata": {"id": "convert"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 5. Dataset 생성\n", "from datasets import Dataset\n\n", "def fmt(e):\n", "    return {'text': f\"<|im_start|>system\\n생기부전문가<|im_end|>\\n<|im_start|>user\\n{e['i']}\\n{e['in']}<|im_end|>\\n<|im_start|>assistant\\n{e['out']}<|im_end|>\"}\n\n", "dataset = Dataset.from_list([fmt(e) for e in examples])\n", "print(f'{len(dataset)} samples')"],
      "metadata": {"id": "dataset"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 6. 모델 로드 + LoRA 설정\n", "import torch\n", "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n", "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\n", "MODEL = 'Qwen/Qwen2.5-3B-Instruct'\n\n", "bnb = BitsAndBytesConfig(\n", "    load_in_4bit=True,\n", "    bnb_4bit_quant_type='nf4',\n", "    bnb_4bit_compute_dtype=torch.bfloat16\n", ")\n\n", "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n", "tokenizer.pad_token = tokenizer.eos_token\n\n", "model = AutoModelForCausalLM.from_pretrained(\n", "    MODEL, quantization_config=bnb, device_map='auto', trust_remote_code=True\n", ")\n", "model = prepare_model_for_kbit_training(model)\n\n", "lora = LoraConfig(\n", "    r=16, lora_alpha=32,\n", "    target_modules=['q_proj','k_proj','v_proj','o_proj','gate_proj','up_proj','down_proj'],\n", "    lora_dropout=0.05, bias='none', task_type='CAUSAL_LM'\n", ")\n", "model = get_peft_model(model, lora)\n", "model.print_trainable_parameters()"],
      "metadata": {"id": "model"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 7. 학습\n", "from transformers import Trainer, TrainingArguments, DataCollatorForLanguageModeling\n\n", "args = TrainingArguments(\n", "    output_dir='./out',\n", "    num_train_epochs=3,\n", "    per_device_train_batch_size=1,\n", "    gradient_accumulation_steps=4,\n", "    learning_rate=2e-4,\n", "    bf16=True,\n", "    logging_steps=10,\n", "    save_strategy='epoch',\n", "    optim='paged_adamw_8bit',\n", "    report_to='none'\n", ")\n\n", "def tokenize(example):\n", "    return tokenizer(example['text'], truncation=True, max_length=2048, padding='max_length')\n\n", "tokenized_dataset = dataset.map(tokenize, remove_columns=['text'])\n", "collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n\n", "trainer = Trainer(\n", "    model=model,\n", "    args=args,\n", "    train_dataset=tokenized_dataset,\n", "    data_collator=collator\n", ")\n\n", "print(f'Training {len(tokenized_dataset)} samples...')\n", "trainer.train()"],
      "metadata": {"id": "train"},
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": ["# 8. 저장 & 다운로드\n", "import shutil\n\n", "model.save_pretrained('./adapter')\n", "tokenizer.save_pretrained('./adapter')\n", "shutil.make_archive('sa_slm_adapter', 'zip', '.', './adapter')\n\n", "print('다운로드 시작...')\n", "files.download('sa_slm_adapter.zip')"],
      "metadata": {"id": "save"},
      "execution_count": null,
      "outputs": []
    }
  ]
}
