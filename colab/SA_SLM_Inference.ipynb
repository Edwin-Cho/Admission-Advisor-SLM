{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# SA_SLM 추론 노트북\n",
        "\n",
        "## 필요 파일\n",
        "- `sa_slm_adapter.zip`: 학습 노트북에서 다운로드한 파일\n",
        "\n",
        "## 실행 전\n",
        "런타임 > 런타임 유형 변경 > **GPU (T4)** 선택"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "install"
      },
      "outputs": [],
      "source": [
        "# 1. 환경 설정\n",
        "%pip install -q torch transformers accelerate peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "upload"
      },
      "outputs": [],
      "source": [
        "# 2. Adapter 업로드\n",
        "from google.colab import files\n",
        "import zipfile, os\n",
        "\n",
        "print('sa_slm_adapter.zip 파일을 업로드하세요')\n",
        "uploaded = files.upload()\n",
        "\n",
        "for f in uploaded:\n",
        "    if f.endswith('.zip'):\n",
        "        zipfile.ZipFile(f).extractall('.')\n",
        "        print(f'{f} 압축 해제 완료')\n",
        "\n",
        "print('OK' if os.path.exists('./adapter') else 'adapter 폴더 없음')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "model"
      },
      "outputs": [],
      "source": [
        "# 3. 모델 로드\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
        "from peft import PeftModel\n",
        "\n",
        "MODEL = 'Qwen/Qwen2.5-3B-Instruct'\n",
        "\n",
        "bnb = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type='nf4',\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL, trust_remote_code=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL, quantization_config=bnb, device_map='auto', trust_remote_code=True\n",
        ")\n",
        "model = PeftModel.from_pretrained(model, './adapter')\n",
        "model.eval()\n",
        "\n",
        "print('Model loaded!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ask"
      },
      "outputs": [],
      "source": [
        "# 4. 추론 함수\n",
        "def ask(prompt):\n",
        "    msgs = [\n",
        "        {'role': 'system', 'content': '생기부 설계 전문가. 성공 사례 기반 차별화된 활동 추천.'},\n",
        "        {'role': 'user', 'content': prompt}\n",
        "    ]\n",
        "    txt = tokenizer.apply_chat_template(msgs, tokenize=False, add_generation_prompt=True)\n",
        "    inp = tokenizer(txt, return_tensors='pt').to(model.device)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        out = model.generate(**inp, max_new_tokens=800, temperature=0.7, do_sample=True)\n",
        "    \n",
        "    return tokenizer.decode(out[0][inp['input_ids'].shape[1]:], skip_special_tokens=True)\n",
        "\n",
        "print('ask() 함수 준비 완료')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test1"
      },
      "outputs": [],
      "source": [
        "# 5. 활동 추천 테스트\n",
        "profile = '''지역: 경기\n",
        "학교: 평준화\n",
        "계열: 공학\n",
        "성적: 3등급대\n",
        "관심: 인공지능, 데이터사이언스\n",
        "가치관: AI 윤리, 디지털 격차 해소\n",
        "목표: 컴퓨터공학'''\n",
        "\n",
        "print(ask('차별화된 활동을 추천하세요.\\n\\n' + profile))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test2"
      },
      "outputs": [],
      "source": [
        "# 6. 세특 문장 생성\n",
        "activity = '''과목: 정보\n",
        "활동: 이미지 분류 데이터셋 클래스 불균형 문제 탐구. 언더/오버샘플링 직접 구현하여 비교 실험.'''\n",
        "\n",
        "print(ask('NEIS 세특 문장으로 작성. 3인칭 서술체.\\n\\n' + activity))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "test3"
      },
      "outputs": [],
      "source": [
        "# 7. 역량 평가\n",
        "statement = '''문장: 코딩 동아리에서 프로그래밍을 배우고 간단한 프로젝트를 수행함.\n",
        "전공: 컴퓨터공학'''\n",
        "\n",
        "print(ask('역량 평가 및 보완 제안.\\n\\n' + statement))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "custom"
      },
      "outputs": [],
      "source": [
        "# 8. 직접 테스트\n",
        "my_profile = '''지역: 서울\n",
        "학교: 평준화\n",
        "계열: 사회\n",
        "성적: 2등급대\n",
        "관심: 경영학, 마케팅\n",
        "가치관: ESG, 사회적 기업\n",
        "목표: 경영학'''\n",
        "\n",
        "print(ask('차별화된 활동을 추천하세요.\\n\\n' + my_profile))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
